{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae174f83-38c6-47a8-a975-7ad69bf566da",
   "metadata": {},
   "source": [
    "Mathematical and Statistical Programming with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1556881c-9fa8-411c-8e88-ec8accd65731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c135d88-92e3-4b0a-a599-90447aa4ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43e5e4b-1197-4375-a0c4-66cbf5badfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc18c835-8742-47c0-a006-ea8f49536eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#1. Display the first 5 elements;\n",
    "print(x[0:5:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1257baa3-fbec-4d6d-85e2-f1406ec04978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "#2. Display every other element:\n",
    "print(x[0:-1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ba8815-503b-4cdf-8d81-1ba17f573f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 7 6 5]\n"
     ]
    }
   ],
   "source": [
    "#3. Display the elements from index 5 in reverse order:\n",
    "print(x[-1:4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12018b24-5428-46ba-9c39-2bdcbf312018",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[12, 5, 2, 4],[7, 6, 8, 8],[1, 6, 7, 7]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090a0dc5-af2c-428b-88f6-f489e76df0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2],\n",
       "       [ 7,  6,  8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Display the first 2 rows and first 3 columns\n",
    "y[:2, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d5b783-00f3-48cf-a251-3cb075a8a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  7,  1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Display first colmn of y:\n",
    "\n",
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011d9bb6-aa09-4378-af1d-a7f2c76cca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  5,  2,  4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.Displau first row of y:\n",
    "\n",
    "y[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82654b87-5e11-4118-bc1f-3d737157b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.real cdc_1 file into notebook\n",
    "data = np.genfromtxt(r\"C:\\Users\\Admin\\Documents\\Course Files\\QADHPYTHON\\data\\cdc_1.csv\", delimiter = ',', skip_header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6148adf7-adf4-4826-bf46-e50944bd3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Calculations:\n",
    "data\n",
    "height = data[:,0]\n",
    "weight = data[:,1]\n",
    "age = data[:,2]\n",
    "minimums = {\"height\": min(height), \"weight\":min(weight), \"age\":min(age)}\n",
    "maximums = {\"height\":max(height), \"weight\":max(weight), \"age\":max(age)}\n",
    "column_length = len(height)\n",
    "means = {\"height\":sum(height)/column_length, \"weight\":sum(weight)/column_length, \"age\":sum(age)/column_length}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8fd53-3954-4dac-92ce-bf6fe8575807",
   "metadata": {},
   "source": [
    "Descriptive Statistics with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c331a7f4-203b-444a-a407-d08381c19623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Read in cnc_nan.csv\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "data =np.genfromtxt(r\"C:\\Users\\Admin\\Documents\\Course Files\\QADHPYTHON\\data\\cdc_nan.csv\", delimiter = ',', skip_header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "472defd1-ebd8-4a58-ab1f-dd2ea898643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Separate heights and weights column\n",
    "heights = data[:,0]\n",
    "weights = data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc2310-21a9-4ba0-88ea-bacf38a7da19",
   "metadata": {},
   "source": [
    "Univariate\n",
    "\n",
    "Measures of Central Tendancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00d184fa-67f3-42f8-ad02-6f920bc8144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median height is: 70.0\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "median_heights = np.median(heights)\n",
    "print(f\"The median height is: {median_heights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "894f948a-da14-4563-a1db-efd3f5e5f545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median weight is: nan\n"
     ]
    }
   ],
   "source": [
    "median_weights = np.median(weights)\n",
    "print(f\"The median weight is: {median_weights}\") # suggesting this has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54843905-eebf-4963-b4c5-bcc0c2802d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in Heights are: 0 \n"
     ]
    }
   ],
   "source": [
    "#2 checking for missing values\n",
    "total_nan_heights = np.sum(np.isnan(heights)) #showing why we were able to calculate median\n",
    "print(f\"The number of missing values in Heights are: {total_nan_heights} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4c333ef-f1d2-4425-aaab-d1ac687fff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in Weights are: 3\n"
     ]
    }
   ],
   "source": [
    "total_nan_weights = np.sum(np.isnan(weights))\n",
    "print(f\"The number of missing values in Weights are: {total_nan_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "004075f4-5109-4657-b460-064c6fe4d06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positions of the missing values in weights are: (array([ 3, 11, 17]),)\n"
     ]
    }
   ],
   "source": [
    "#3 positions of missing values\n",
    "nan_positions_weights = np.where(np.isnan(weights))\n",
    "print(f\"The positions of the missing values in weights are: {nan_positions_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7131e8d-12de-4c61-bcee-b0d1c01b4ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median weights after removing missing values is: 185.0\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "median_weight_clean = np.nanmedian(weights)\n",
    "print(f\"The median weights after removing missing values is: {median_weight_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a0a00-f2f3-4db9-975a-2978fca63739",
   "metadata": {},
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f081a0d-8163-4d17-8333-2791558e8f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rounded mean value of Heights is: 70.25164594001463\n"
     ]
    }
   ],
   "source": [
    "mean_height = np.mean(heights)\n",
    "print(f\"The mean value of Heights is: {mean_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e325041f-5ac2-4e31-b92c-8277e7975e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of Weights is: 189.3251097637466 \n"
     ]
    }
   ],
   "source": [
    "mean_weight = np.nanmean(weights)\n",
    "print(f\"The mean value of Weights is: {mean_weight} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066c83d-4423-4b54-a585-17a898c51474",
   "metadata": {},
   "source": [
    "Measures of Spread (variability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7977621-d919-4713-a699-cfc75fb98946",
   "metadata": {},
   "source": [
    "Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca711027-eb36-4b32-bdfe-6b9022d968d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of the heights is: 44\n"
     ]
    }
   ],
   "source": [
    "range_heights = int(np.nanmax(heights)-np.nanmin(heights))\n",
    "print(f\"The range of the heights is: {range_heights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f054e8d-6c7e-4be1-b66d-e3aad15f3a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of the weights is: 422\n"
     ]
    }
   ],
   "source": [
    "range_weights = int(np.nanmax(weights) - np.nanmin(weights))\n",
    "print(f\"The range of the weights is: {range_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c20dbfc8-4e0a-4118-b66c-bca5536f0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower and upper quartiles of Heights are 68 and 72.\n",
      "Thus, the interquartile range is 4.\n"
     ]
    }
   ],
   "source": [
    "height_upper_quartile = int(np.nanpercentile(heights, 75))\n",
    "height_lower_quartile = int(np.nanpercentile(heights, 25))\n",
    "heights_IQR = int(height_upper_quartile - height_lower_quartile)\n",
    "print(f\"The lower and upper quartiles of Heights are {height_lower_quartile} and {height_upper_quartile}.\\nThus, the interquartile range is {heights_IQR }.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8353c76e-3dac-4575-9cac-04fb986c4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower and upper quartiles of weights are 165 and 210.\n",
      "Thus, the interquartile range is 45.\n"
     ]
    }
   ],
   "source": [
    "weight_upper_quartile = int(np.nanpercentile(weight, 75))\n",
    "weight_lower_quartile = int(np.nanpercentile(weights, 25))\n",
    "weights_IQR = int(weight_upper_quartile - weight_lower_quartile)\n",
    "print(f\"The lower and upper quartiles of weights are {weight_lower_quartile} and {weight_upper_quartile}.\\nThus, the interquartile range is {weights_IQR }.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59e262-b382-4d00-9039-8abd7fd559f9",
   "metadata": {},
   "source": [
    "Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13d88942-3f5f-4267-9fcd-18c53cbcfa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rounded population and sample variance of the Heights are: 9.0545 and 9.0554.\n"
     ]
    }
   ],
   "source": [
    "population_variance_height = round(np.nanvar(heights),4)\n",
    "sample_variance_height = round(np.nanvar(heights, ddof=1), 4)\n",
    "print(f\"The rounded population and sample variance of the Heights are: {population_variance_height} and {sample_variance_height}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2faaffbe-1951-4315-a0e4-5a04ce4729ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rounded population and sample variance of the Weights are: 1336.1876 and 1336.3273.\n"
     ]
    }
   ],
   "source": [
    "population_variance_weight = round(np.nanvar(weights),4)\n",
    "sample_variance_weight = round(np.nanvar(weights, ddof=1), 4)\n",
    "print(f\"The rounded population and sample variance of the Weights are: {population_variance_weight} and {sample_variance_weight}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d277816-3b32-49f3-aad5-eef3bebffc59",
   "metadata": {},
   "source": [
    "Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15543f1a-55ca-48f7-b1e2-56713529ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_std_height = round(population_variance_height**(0.5),4)\n",
    "sample_std_height = round(sample_variance_height**(0.5), 4)\n",
    "population_std_weight = round(population_variance_weight**(0.5),4)\n",
    "sample_std_weight = round(sample_variance_weight**(0.5),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c919e23-40db-4332-ae07-d5e0b4e0bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rounded population and sample standard deviation of the Heights are: 3.0091 and 3.0092.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rounded population and sample standard deviation of the Heights are: {population_std_height} and {sample_std_height}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eeb3f358-5119-41d1-86ca-6bd4f8adcde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rounded population and sample standard deviation of the Weights are: 36.5539 and 36.5558.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rounded population and sample standard deviation of the Weights are: {population_std_weight} and {sample_std_weight}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e701017-6c54-49c9-b2a0-b8362851e761",
   "metadata": {},
   "source": [
    "Bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f6b51-e043-4f7f-87c5-78a39df88573",
   "metadata": {},
   "source": [
    "Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cfbae593-0336-412b-adab-c438e8cf8cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenghth of the heights and weights arrays are: 9569 & 9566.\n",
      "So, now the legnth of the heights array is 9566\n",
      "The Covariance between the adjusted Heights and Weights are: \n",
      "[[   9.04833427    5.53401567]\n",
      " [   5.53401567 1336.32732971]]\n"
     ]
    }
   ],
   "source": [
    "covariance = np.cov(heights,weights, ddof=1)  #this cannot be calculated given the missing values therefore let us clean the data\n",
    "weights_cleaned = weights[~np.isnan(weights)]\n",
    "length_weights = len(weights_cleaned)\n",
    "length_heights=len(heights)\n",
    "print(f\"The lenghth of the heights and weights arrays are: {length_heights} & {length_weights}.\")\n",
    "#we note that heights is larger since we cleaned the wreights set\n",
    "#hence, make the legnths equivalent by randomly removign 3 points\n",
    "randompoints = np.random.choice (heights.size, size = 3, replace=False)\n",
    "heights_shortened = np.delete(heights, randompoints)\n",
    "length_heights_shortened = len(heights_shortened)\n",
    "print(f\"So, now the legnth of the heights array is {length_heights_shortened}\")\n",
    "#now we can fairly calculate the covariance:\n",
    "covariance_cleaned = np.cov(heights_shortened, weights_cleaned, ddof=1)\n",
    "print(f\"The Covariance between the adjusted Heights and Weights are: \\n{covariance_cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6b97cb96-1bf6-4b40-8d23-087c81bfd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Left diagonal values are the variance figures we have calculated before and the right diagonal value show the covariance between height and weight. \n",
      "Showing that as one increase in POSITIVE DIRECTION, the other will also INCREASES linearly in a POSITIVE DIRECTION, with a STRENGTH of 5.\n",
      "The strength is harder to interpret for covariance since it is not a scaled value unlike correlaiton.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Left diagonal values are the variance figures we have calculated before and the right diagonal value show the covariance between height and weight. \\nShowing that as one increase in POSITIVE DIRECTION, the other will also INCREASES linearly in a POSITIVE DIRECTION, with a STRENGTH of 5.\\nThe strength is harder to interpret for covariance since it is not a scaled value unlike correlaiton.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9508a-badc-42ef-bc93-929999fcf5ca",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d90806-1343-4e17-934f-ddee80967b82",
   "metadata": {},
   "source": [
    "We shall use the adjusted arrays for height and weight to circumvent the NaN and dimension issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b501b628-ab5a-4630-80d2-eaaa469a06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Correlation between the adjusted Heights and Weights are: \n",
      "[[1.         0.05032684]\n",
      " [0.05032684 1.        ]].\n"
     ]
    }
   ],
   "source": [
    "correlation_cleaned = np.corrcoef(heights_shortened, weights_cleaned)\n",
    "print(f\"The Correlation between the adjusted Heights and Weights are: \\n{correlation_cleaned}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ecd1fc64-e143-4bf3-8ef8-1e8745d02304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Ignore both values of 1 on the left diagonal as the correlation of a dataset with itself will always be 1. \n",
      "2.The values along the right diagonal are equivalent since the correlation is symmetric.\n",
      "3.The value indicates that if one variance, height or weight, increases, the other will also icnrease with a strength of 0.05.\n"
     ]
    }
   ],
   "source": [
    "print(f\"1.Ignore both values of 1 on the left diagonal as the correlation of a dataset with itself will always be 1. \\n2.The values along the right diagonal are equivalent since the correlation is symmetric.\\n3.The value indicates that if one variance, height or weight, increases, the other will also icnrease with a strength of 0.05.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b30a6-505c-4fd1-9513-332084d258fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962116b-abde-4ee4-9ed5-452ccfcc6019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
